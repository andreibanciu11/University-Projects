{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8210b19",
   "metadata": {},
   "source": [
    "## A.I. Assignment 5\n",
    "\n",
    "## Learning Goals\n",
    "\n",
    "By the end of this lab, you should be able to:\n",
    "* Get more familiar with tensors in pytorch \n",
    "* Create a simple multilayer perceptron model with pytorch\n",
    "* Visualise the parameters\n",
    "\n",
    "\n",
    "### Task\n",
    "\n",
    "Build a fully connected feed forward network that adds two bits. Determine the a propper achitecture for this network (what database you use for this problem? how many layers? how many neurons on each layer? what is the activation function? what is the loss function? etc)\n",
    "\n",
    "Create at least 3 such networks and compare their performance (how accurate they are?, how farst they are trained to get at 1 accuracy?)\n",
    "\n",
    "Display for the best one the weights for each layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3614e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "5ee7e7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=2, out_features=10, bias=True)\n",
      "  (1): Sigmoid()\n",
      "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model1 = nn.Sequential(nn.Linear(2,3), nn.Sigmoid(), nn.Linear(3, 2), nn.Sigmoid())\n",
    "model2 = nn.Sequential(nn.Linear(2,3), nn.Tanh(), nn.Linear(3, 2), nn.Sigmoid())\n",
    "model3 = nn.Sequential(nn.Linear(2,3), nn.ReLU(), nn.Linear(3, 2), nn.Sigmoid())\n",
    "\n",
    "model4 = nn.Sequential(nn.Linear(2,10), nn.Sigmoid(), nn.Linear(10, 2), nn.Sigmoid())\n",
    "model5 = nn.Sequential(nn.Linear(2,10), nn.Tanh(), nn.Linear(10, 2), nn.Sigmoid())\n",
    "model6 = nn.Sequential(nn.Linear(2,10), nn.ReLU(), nn.Linear(10, 2), nn.Sigmoid())\n",
    "\n",
    "model7 = nn.Sequential(nn.Linear(2,10), nn.Tanh(), nn.Linear(10,10), nn.Tanh(), nn.Linear(10, 2))\n",
    "model8 = nn.Sequential(nn.Linear(2,10), nn.Tanh(), nn.Linear(10,10), nn.Tanh(), nn.Linear(10, 2), nn.Sigmoid())\n",
    "model9 = nn.Sequential(nn.Linear(2,10), nn.Tanh(), nn.Linear(10,10), nn.Tanh(), nn.Linear(10, 2), nn.Tanh())\n",
    "\n",
    "model = nn.Sequential(nn.Linear(2,3), nn.Tanh(), nn.Linear(3, 2), nn.Tanh())\n",
    "model=model4\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665ae958",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "e26f0d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "data_in = torch.tensor([[0.,0.], [0., 1.], [1., 0.], [1., 1.]]).float()\n",
    "print(data_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "4fb16bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "data_target = torch.tensor([[0.,0.], [1., 0.], [1., 0.], [0., 1.]]).float()\n",
    "print(data_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "69d920ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "cde91f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.5965\n",
      "Epoch [200/1000], Loss: 0.5795\n",
      "Epoch [300/1000], Loss: 0.5740\n",
      "Epoch [400/1000], Loss: 0.5713\n",
      "Epoch [500/1000], Loss: 0.5697\n",
      "Epoch [600/1000], Loss: 0.5687\n",
      "Epoch [700/1000], Loss: 0.5679\n",
      "Epoch [800/1000], Loss: 0.5674\n",
      "Epoch [900/1000], Loss: 0.5669\n",
      "Epoch [1000/1000], Loss: 0.5666\n"
     ]
    }
   ],
   "source": [
    "num_epochs=1000\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    data_out = model(data_in)\n",
    "    loss = criterion(data_out, data_target)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if(epoch+1) % 100 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff3ec1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "c1a7518b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=2, out_features=3, bias=True)\n",
      "  (1): Sigmoid()\n",
      "  (2): Linear(in_features=3, out_features=2, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")\n",
      "Epoch [1000/10000], Loss: 0.2148\n",
      "Epoch [2000/10000], Loss: 0.2044\n",
      "Epoch [3000/10000], Loss: 0.1857\n",
      "Epoch [4000/10000], Loss: 0.1645\n",
      "Epoch [5000/10000], Loss: 0.1475\n",
      "Epoch [6000/10000], Loss: 0.1355\n",
      "Epoch [7000/10000], Loss: 0.1243\n",
      "Epoch [8000/10000], Loss: 0.1100\n",
      "Epoch [9000/10000], Loss: 0.0911\n",
      "Epoch [10000/10000], Loss: 0.0699\n",
      "tensor([[0., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.]])\n",
      "tensor([[0., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.]])\n",
      "Validation Accuracy: 100.00%\n",
      "[tensor([[-1.9818, -1.6564],\n",
      "        [ 2.8434,  2.9709],\n",
      "        [-2.8151, -2.8721]]), tensor([ 0.8426, -1.0325,  4.2563]), tensor([[-1.3465,  1.9564,  2.5433],\n",
      "        [-2.9834,  3.4952, -4.9553]]), tensor([-2.7091, -0.4530])]\n"
     ]
    }
   ],
   "source": [
    "model1 = nn.Sequential(nn.Linear(2,3), nn.Sigmoid(), nn.Linear(3, 2), nn.Sigmoid())\n",
    "model2 = nn.Sequential(nn.Linear(2,3), nn.Tanh(), nn.Linear(3, 2), nn.Sigmoid())\n",
    "model3 = nn.Sequential(nn.Linear(2,3), nn.ReLU(), nn.Linear(3, 2), nn.Sigmoid())\n",
    "\n",
    "model4 = nn.Sequential(nn.Linear(2,10), nn.Sigmoid(), nn.Linear(10, 2), nn.Sigmoid())\n",
    "model5 = nn.Sequential(nn.Linear(2,10), nn.Tanh(), nn.Linear(10, 2), nn.Sigmoid())\n",
    "model6 = nn.Sequential(nn.Linear(2,10), nn.ReLU(), nn.Linear(10, 2), nn.Sigmoid())\n",
    "\n",
    "model7 = nn.Sequential(nn.Linear(2,10), nn.Tanh(), nn.Linear(10,10), nn.Tanh(), nn.Linear(10, 2))\n",
    "model8 = nn.Sequential(nn.Linear(2,10), nn.Tanh(), nn.Linear(10,10), nn.Tanh(), nn.Linear(10, 2), nn.Sigmoid())\n",
    "model9 = nn.Sequential(nn.Linear(2,10), nn.Tanh(), nn.Linear(10,10), nn.Tanh(), nn.Linear(10, 2), nn.Tanh())\n",
    "\n",
    "model10 = nn.Sequential(nn.Linear(2,3), nn.Tanh(), nn.Linear(3, 2), nn.Tanh())\n",
    "\n",
    "\n",
    "model = model1\n",
    "print(model)\n",
    "\n",
    "\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "\n",
    "\n",
    "num_epochs=10000\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    data_out = model(data_in)\n",
    "    loss = criterion(data_out, data_target)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if(epoch+1) % 1000 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    data_out = model(data_in)\n",
    "    predicted = torch.where(data_out < 0.5, 0., 1.)\n",
    "    \n",
    "    print(predicted)\n",
    "    print(data_target)\n",
    "    \n",
    "    total += data_target.size(0)\n",
    "    correct += torch.where((predicted == data_target).sum(1) == data_target.size(1), 1, 0).sum()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Validation Accuracy: {accuracy:.2f}%\")\n",
    "    \n",
    "print(list(model.state_dict().values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "4cdf09ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bea66c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29c65a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
